{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiaerii/mash/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22%D0%94%D0%BE%D0%B1%D1%80%D0%BE_%D0%BF%D0%BE%D0%B6%D0%B0%D0%BB%D0%BE%D0%B2%D0%B0%D1%82%D1%8C_%D0%B2_Colab!%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 pandas scikit-learn pymorphy3 sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yUW5eGOfp9b",
        "outputId": "f93e8d7a-3549-4054-b3fc-5cfe3a8898bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.12/dist-packages (2.0.6)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (2.4.417150.4580142)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (75.2.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pymorphy3\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "BASE = \"https://lenta.ru\"\n",
        "\n",
        "def parse_full_text(url: str) -> str:\n",
        "    \"\"\"Парсинг полного текста новости по ссылке.\"\"\"\n",
        "    try:\n",
        "        # Добавляем заголовки для имитации браузера\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        r = requests.get(url, headers=headers, timeout=10)\n",
        "        r.raise_for_status()\n",
        "        r.encoding = 'utf-8'  # Явно указываем кодировку\n",
        "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "\n",
        "        # Более гибкий поиск текстовых блоков\n",
        "        # Ищем по различным классам, которые могут содержать текст статьи\n",
        "        text_blocks = []\n",
        "\n",
        "        # 1. Ищем параграфы с классами, содержащими 'body'\n",
        "        text_blocks = soup.find_all(\"p\", class_=lambda x: x and (\"body\" in str(x).lower() or \"article\" in str(x).lower()))\n",
        "\n",
        "        # 2. Если не нашли, ищем по тегам внутри article\n",
        "        if not text_blocks:\n",
        "            article = soup.find(\"article\")\n",
        "            if article:\n",
        "                text_blocks = article.find_all(\"p\")\n",
        "\n",
        "        # 3. Последний вариант - все параграфы\n",
        "        if not text_blocks:\n",
        "            text_blocks = soup.find_all(\"p\")\n",
        "\n",
        "        # Фильтруем слишком короткие блоки\n",
        "        filtered_blocks = []\n",
        "        for block in text_blocks:\n",
        "            text = block.get_text(strip=True)\n",
        "            if len(text) > 20:  # Игнорируем очень короткие блоки\n",
        "                filtered_blocks.append(text)\n",
        "\n",
        "        # Объединяем текст\n",
        "        text = \" \".join(filtered_blocks)\n",
        "        return text[:1500]  # Ограничиваем размер для экономии памяти\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при парсинге текста {url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def parse_news(news_count=50, date_str: str | None = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Сбор новостей с главной страницы или по конкретной дате.\n",
        "    news_count: сколько новостей собрать\n",
        "    date_str: строка \"YYYY-MM-DD\" или None (тогда берём главную)\n",
        "    \"\"\"\n",
        "    # Добавляем заголовки для запросов\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    if date_str:\n",
        "        try:\n",
        "            y, m, d = map(int, date_str.split(\"-\"))\n",
        "            url = f\"{BASE}/news/{y:04d}/{m:02d}/{d:02d}/\"\n",
        "        except:\n",
        "            print(\"Неверный формат даты. Используется главная страница.\")\n",
        "            url = BASE + \"/\"\n",
        "    else:\n",
        "        url = BASE + \"/\"\n",
        "\n",
        "    print(\"Парсим URL:\", url)\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, headers=headers, timeout=10)\n",
        "        r.raise_for_status()\n",
        "        r.encoding = 'utf-8'\n",
        "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "        news = []\n",
        "\n",
        "        items = []\n",
        "\n",
        "        if date_str and \"/news/\" in url:\n",
        "            # Для страницы с конкретной датой\n",
        "            prefix = f\"/news/{y:04d}/{m:02d}/{d:02d}/\"\n",
        "            all_links = soup.find_all(\"a\", href=True)\n",
        "            items = [a for a in all_links if a[\"href\"].startswith(prefix)]\n",
        "            print(f\"Найдено ссылок на новости за {date_str}: {len(items)}\")\n",
        "        else:\n",
        "            # Для главной страницы\n",
        "            # Ищем по различным классам\n",
        "            items = soup.find_all(\"a\", class_=lambda x: x and any(\n",
        "                word in str(x).lower() for word in [\"card\", \"news\", \"item\", \"topnews\", \"banner\", \"tile\"]\n",
        "            ))\n",
        "\n",
        "            # Если не нашли по классам, ищем все ссылки с /news/\n",
        "            if len(items) < news_count:\n",
        "                all_links = soup.find_all(\"a\", href=True)\n",
        "                items = [a for a in all_links if \"/news/\" in a.get(\"href\", \"\")]\n",
        "\n",
        "        print(f\"Всего найдено потенциальных новостей: {len(items)}\")\n",
        "\n",
        "        for idx, a in enumerate(items):\n",
        "            if len(news) >= news_count:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                # Заголовок\n",
        "                title = \"\"\n",
        "                title_elem = a.find([\"h3\", \"span\", \"div\"])\n",
        "                if title_elem:\n",
        "                    title = title_elem.get_text(strip=True)\n",
        "                else:\n",
        "                    title = a.get_text(strip=True)\n",
        "\n",
        "                # Пропускаем слишком короткие заголовки\n",
        "                if len(title) < 10:\n",
        "                    continue\n",
        "\n",
        "                # Ссылка\n",
        "                link = a.get(\"href\")\n",
        "                if not link:\n",
        "                    continue\n",
        "\n",
        "                if link and not link.startswith(\"http\"):\n",
        "                    if link.startswith(\"//\"):\n",
        "                        link = \"https:\" + link\n",
        "                    else:\n",
        "                        link = BASE + link\n",
        "\n",
        "                # Полный текст\n",
        "                print(f\"Обработка новости {len(news)+1}/{news_count}: {title[:50]}...\")\n",
        "                full_text = parse_full_text(link)\n",
        "\n",
        "                news.append({\n",
        "                    \"date\": date_str or dt.date.today().isoformat(),\n",
        "                    \"title\": title,\n",
        "                    \"link\": link,\n",
        "                    \"full_text\": full_text,\n",
        "                    \"text_length\": len(full_text)\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка при обработке новости {idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "        df = pd.DataFrame(news)\n",
        "        print(f\"Собрано новостей: {len(df)}\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при парсинге страницы: {e}\")\n",
        "        # Возвращаем пустой DataFrame\n",
        "        return pd.DataFrame(columns=[\"date\", \"title\", \"link\", \"full_text\", \"text_length\"])"
      ],
      "metadata": {
        "id": "AKyw4DbHfw7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Настройки\n",
        "NEWS_COUNT = 50\n",
        "DATE_STR = None  # Можно указать дату, например \"2024-03-15\"\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\" СБОР НОВОСТЕЙ С LENTA.RU\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Собираем новости\n",
        "df = parse_news(news_count=NEWS_COUNT, date_str=DATE_STR)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\" РЕЗУЛЬТАТЫ СБОРА ДАННЫХ\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Показываем статистику\n",
        "print(f\"\\n Собрано новостей: {len(df)}\")\n",
        "print(f\" Период: {df['date'].iloc[0]}\")\n",
        "print(f\" Средняя длина текста: {df['text_length'].mean():.0f} символов\")\n",
        "\n",
        "# Создаем красивую таблицу для отображения\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\" ТАБЛИЦА НОВОСТЕЙ (первые 10 записей)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Создаем стилизованную таблицу\n",
        "styled_df = df.head(10).copy()\n",
        "styled_df['№'] = range(1, len(styled_df) + 1)\n",
        "styled_df['Заголовок'] = styled_df['title'].apply(lambda x: x[:80] + '...' if len(x) > 80 else x)\n",
        "styled_df['Длина текста'] = styled_df['text_length']\n",
        "styled_df['Дата'] = styled_df['date']\n",
        "styled_df['Ссылка'] = styled_df['link'].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">Открыть</a>')\n",
        "\n",
        "# Отображаем таблицу\n",
        "display_df = styled_df[['№', 'Дата', 'Заголовок', 'Длина текста', 'Ссылка']]\n",
        "\n",
        "# Создаем HTML таблицу с стилями\n",
        "html = \"\"\"\n",
        "<style>\n",
        ".news-table {\n",
        "    width: 100%;\n",
        "    border-collapse: collapse;\n",
        "    font-family: Arial, sans-serif;\n",
        "    margin: 20px 0;\n",
        "}\n",
        ".news-table th {\n",
        "    background-color: #4CAF50;\n",
        "    color: white;\n",
        "    padding: 12px;\n",
        "    text-align: left;\n",
        "    border: 1px solid #ddd;\n",
        "}\n",
        ".news-table td {\n",
        "    padding: 10px;\n",
        "    border: 1px solid #ddd;\n",
        "}\n",
        ".news-table tr:nth-child(even) {\n",
        "    background-color: #f2f2f2;\n",
        "}\n",
        ".news-table tr:hover {\n",
        "    background-color: #ddd;\n",
        "}\n",
        ".news-link {\n",
        "    color: #0066cc;\n",
        "    text-decoration: none;\n",
        "}\n",
        ".news-link:hover {\n",
        "    text-decoration: underline;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "html += \"<table class='news-table'>\"\n",
        "html += \"<tr><th>№</th><th>Дата</th><th>Заголовок</th><th>Длина текста</th><th>Ссылка</th></tr>\"\n",
        "\n",
        "for _, row in display_df.iterrows():\n",
        "    html += f\"\"\"\n",
        "    <tr>\n",
        "        <td>{row['№']}</td>\n",
        "        <td>{row['Дата']}</td>\n",
        "        <td>{row['Заголовок']}</td>\n",
        "        <td>{row['Длина текста']}</td>\n",
        "        <td>{row['Ссылка']}</td>\n",
        "    </tr>\n",
        "    \"\"\"\n",
        "\n",
        "html += \"</table>\"\n",
        "\n",
        "# Добавляем статистику под таблицей\n",
        "html += f\"\"\"\n",
        "<div style=\"margin-top: 20px; padding: 10px; background-color: #f8f9fa; border-left: 4px solid #4CAF50;\">\n",
        "    <h4> Статистика:</h4>\n",
        "    <p>• Всего новостей: <strong>{len(df)}</strong></p>\n",
        "    <p>• Средняя длина текста: <strong>{df['text_length'].mean():.0f}</strong> символов</p>\n",
        "    <p>• Минимальная длина: <strong>{df['text_length'].min()}</strong> символов</p>\n",
        "    <p>• Максимальная длина: <strong>{df['text_length'].max()}</strong> символов</p>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# Выводим HTML\n",
        "display(HTML(html))\n",
        "\n",
        "# Также показываем стандартный DataFrame для полноты информации\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\" ПОЛНЫЙ DATAFRAME С НОВОСТЯМИ\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nРазмер DataFrame: {df.shape}\")\n",
        "print(f\"Колонки: {list(df.columns)}\")\n",
        "\n",
        "# Показываем первые 5 строк в обычном виде\n",
        "print(\"\\nПервые 5 строк DataFrame:\")\n",
        "pd.set_option('display.max_colwidth', 80)  # Увеличиваем ширину колонок\n",
        "print(df[['date', 'title', 'text_length']].head())\n",
        "pd.reset_option('display.max_colwidth')"
      ],
      "metadata": {
        "id": "jjrPdf8ngtnK",
        "outputId": "37b16384-8422-4a3e-c675-459d90a1b1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " СБОР НОВОСТЕЙ С LENTA.RU\n",
            "======================================================================\n",
            "Парсим URL: https://lenta.ru/\n",
            "Всего найдено потенциальных новостей: 158\n",
            "Обработка новости 1/50: В Киеве раздались взрывы01:41...\n",
            "Обработка новости 2/50: В Европе подвели итоги противостояния с Россией01:...\n",
            "Обработка новости 3/50: Жители российского региона сообщили о взрывах и вс...\n",
            "Обработка новости 4/50: Зеленский прокомментировал переговоры Уиткоффа и П...\n",
            "Обработка новости 5/50: Германия передвинула истребители ближе к границам ...\n",
            "Обработка новости 6/50: Трамп ужесточил правила для мигрантов01:05...\n",
            "Обработка новости 7/50: Самая красивая женщина в мире показала фото в крош...\n",
            "Обработка новости 8/50: Названы тревожные причины отсутствия секса в паре0...\n",
            "Обработка новости 9/50: В США предложили запретить Nvidia экспортировать ч...\n",
            "Обработка новости 10/50: Мерц высказался об опасениях Бельгии по поводу акт...\n",
            "Обработка новости 11/50: Дмитриев обратился к Мерцу00:29...\n",
            "Обработка новости 12/50: Киркоров подарил Собчак сумку-ежа почти за 100 тыс...\n",
            "Обработка новости 13/50: Российский штурмовик рассказал о «правиле 60 секун...\n",
            "Обработка новости 14/50: Путина рассмешил вопрос про Крым. Что он сказал ин...\n",
            "Обработка новости 15/50: Раскрыты корни теории заговора о двойниках Путина1...\n",
            "Обработка новости 16/50: Все новости...\n",
            "Обработка новости 17/50: Все эксклюзивы...\n",
            "Обработка новости 18/50: Помощника Путина пригласили в зоопарк после необыч...\n",
            "Обработка новости 19/50: В США разработают «Коготь» для F-3500:30...\n",
            "Обработка новости 20/50: Атеистка рассказала о встрече с Богом после аварии...\n",
            "Обработка новости 21/50: Мерц отложил запланированную поездку ради перегово...\n",
            "Обработка новости 22/50: Президент «Барселоны» вспомнил о Путине во время р...\n",
            "Обработка новости 23/50: Трамп помирил еще две страны ради редкоземельных м...\n",
            "Обработка новости 24/50: Трамп пошутил над названием Кеннеди-центра00:04...\n",
            "Обработка новости 25/50: США продлили срок международных операций с «Лукойл...\n",
            "Обработка новости 26/50: Голубей в носках не пропустили в Россию23:52, 4 де...\n",
            "Обработка новости 27/50: Российский аэропорт приостановил работу ради безоп...\n",
            "Обработка новости 28/50: Мизулина свяжется с Роскомнадзором из-за блокировк...\n",
            "Обработка новости 29/50: На Украине заявили о «худшем периоде» для страны с...\n",
            "Обработка новости 30/50: Над Россией сбили десятки беспилотников ВСУ за три...\n",
            "Обработка новости 31/50: Россиянин жестоко избил собак в подъезде многоэтаж...\n",
            "Обработка новости 32/50: Курск подвергся атаке украинских беспилотников23:2...\n",
            "Обработка новости 33/50: Тысячи украинских беженцев оказались под риском де...\n",
            "Обработка новости 34/50: Россиянин поставил на матч КХЛ и выиграл почти 7,3...\n",
            "Обработка новости 35/50: Аналитик раскрыл подробности будущих переговоров С...\n",
            "Обработка новости 36/50: Тарпищев отреагировал на решение восьмой ракетки Р...\n",
            "Обработка новости 37/50: Адвокат объяснил истребование Верховным судом мате...\n",
            "Обработка новости 38/50: Россия отвергла обвинения в причастности к инциден...\n",
            "Обработка новости 39/50: Зеленский анонсировал решение по новому главе офис...\n",
            "Обработка новости 40/50: Путин сравнил индийских журналистов со шпионами22:...\n",
            "Обработка новости 41/50: Бывший советник Пентагона дал совет Украине насчет...\n",
            "Обработка новости 42/50: В России оценили возможность возвращения в G822:33...\n",
            "Обработка новости 43/50: В США сделали заявление после встречи Путина и Уит...\n",
            "Обработка новости 44/50: Путин пошутил о встрече с Уиткоффом22:21, 4 декабр...\n",
            "Обработка новости 45/50: Охлобыстин рассказал о необычной семейной традиции...\n",
            "Обработка новости 46/50: ВСУ атаковали российский город22:16, 4 декабря 202...\n",
            "Обработка новости 47/50: Путин назвал способ избежать ошибок22:16, 4 декабр...\n",
            "Обработка новости 48/50: В Европе задумались о новом плане по Украине22:00,...\n",
            "Обработка новости 49/50: «Евровидение» подверглось бойкоту из-за Израиля21:...\n",
            "Обработка новости 50/50: Путин высказался о влиянии Telegram21:54, 4 декабр...\n",
            "Собрано новостей: 50\n",
            "\n",
            "======================================================================\n",
            " РЕЗУЛЬТАТЫ СБОРА ДАННЫХ\n",
            "======================================================================\n",
            "\n",
            " Собрано новостей: 50\n",
            " Период: 2025-12-04\n",
            " Средняя длина текста: 850 символов\n",
            "\n",
            "======================================================================\n",
            " ТАБЛИЦА НОВОСТЕЙ (первые 10 записей)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              ".news-table {\n",
              "    width: 100%;\n",
              "    border-collapse: collapse;\n",
              "    font-family: Arial, sans-serif;\n",
              "    margin: 20px 0;\n",
              "}\n",
              ".news-table th {\n",
              "    background-color: #4CAF50;\n",
              "    color: white;\n",
              "    padding: 12px;\n",
              "    text-align: left;\n",
              "    border: 1px solid #ddd;\n",
              "}\n",
              ".news-table td {\n",
              "    padding: 10px;\n",
              "    border: 1px solid #ddd;\n",
              "}\n",
              ".news-table tr:nth-child(even) {\n",
              "    background-color: #f2f2f2;\n",
              "}\n",
              ".news-table tr:hover {\n",
              "    background-color: #ddd;\n",
              "}\n",
              ".news-link {\n",
              "    color: #0066cc;\n",
              "    text-decoration: none;\n",
              "}\n",
              ".news-link:hover {\n",
              "    text-decoration: underline;\n",
              "}\n",
              "</style>\n",
              "<table class='news-table'><tr><th>№</th><th>Дата</th><th>Заголовок</th><th>Длина текста</th><th>Ссылка</th></tr>\n",
              "    <tr>\n",
              "        <td>1</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>В Киеве раздались взрывы01:41</td>\n",
              "        <td>557</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/v-kieve-razdalis-vzryvy/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <td>2</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>В Европе подвели итоги противостояния с Россией01:41</td>\n",
              "        <td>1093</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/v-evrope-podveli-itogi-protivostoyaniya-s-rossiey/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <td>3</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>Жители российского региона сообщили о взрывах и вспышках01:39</td>\n",
              "        <td>528</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/zhiteli-rossiyskogo-regiona-soobschili-o-vzryvah-i-vspyshkah/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <td>4</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>Зеленский прокомментировал переговоры Уиткоффа и Путина01:18</td>\n",
              "        <td>891</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/zelenskiy-prokommentiroval-peregovory-uitkoffa-i-putina/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <td>5</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>Германия передвинула истребители ближе к границам России01:17</td>\n",
              "        <td>685</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/germaniya-peredvinula-istrebiteli-blizhe-k-granitsam-rossii/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <td>6</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>Трамп ужесточил правила для мигрантов01:05</td>\n",
              "        <td>1151</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/tramp-uzhestochil-pravila-dlya-migrantov/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <td>7</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>Самая красивая женщина в мире показала фото в крошечном бюстгальтере01:02</td>\n",
              "        <td>870</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/samaya-krasivaya-zhenschina-v-mire-pokazala-foto-v-kroshechnom-byustgaltere/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <td>8</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>Названы тревожные причины отсутствия секса в паре01:02</td>\n",
              "        <td>1444</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/nazvany-trevozhnye-prichiny-otsutstviya-seksa-v-pare/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <td>9</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>В США предложили запретить Nvidia экспортировать чипы в Россию00:44</td>\n",
              "        <td>870</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/v-ssha-predlozhili-zapretit-nvidia-eksportirovat-chipy-v-rossiyu/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <td>10</td>\n",
              "        <td>2025-12-04</td>\n",
              "        <td>Мерц высказался об опасениях Бельгии по поводу активов России00:44</td>\n",
              "        <td>1329</td>\n",
              "        <td><a href=\"https://lenta.ru/news/2025/12/05/merts-vyskazalsya-ob-opaseniyah-belgii-po-povodu-aktivov-rossii/\" target=\"_blank\">Открыть</a></td>\n",
              "    </tr>\n",
              "    </table>\n",
              "<div style=\"margin-top: 20px; padding: 10px; background-color: #f8f9fa; border-left: 4px solid #4CAF50;\">\n",
              "    <h4> Статистика:</h4>\n",
              "    <p>• Всего новостей: <strong>50</strong></p>\n",
              "    <p>• Средняя длина текста: <strong>850</strong> символов</p>\n",
              "    <p>• Минимальная длина: <strong>0</strong> символов</p>\n",
              "    <p>• Максимальная длина: <strong>1500</strong> символов</p>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " ПОЛНЫЙ DATAFRAME С НОВОСТЯМИ\n",
            "======================================================================\n",
            "\n",
            "Размер DataFrame: (50, 5)\n",
            "Колонки: ['date', 'title', 'link', 'full_text', 'text_length']\n",
            "\n",
            "Первые 5 строк DataFrame:\n",
            "         date                                                          title  \\\n",
            "0  2025-12-04                                  В Киеве раздались взрывы01:41   \n",
            "1  2025-12-04           В Европе подвели итоги противостояния с Россией01:41   \n",
            "2  2025-12-04  Жители российского региона сообщили о взрывах и вспышках01:39   \n",
            "3  2025-12-04   Зеленский прокомментировал переговоры Уиткоффа и Путина01:18   \n",
            "4  2025-12-04  Германия передвинула истребители ближе к границам России01:17   \n",
            "\n",
            "   text_length  \n",
            "0          557  \n",
            "1         1093  \n",
            "2          528  \n",
            "3          891  \n",
            "4          685  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Очистка текста:\n",
        "    - в нижний регистр\n",
        "    - удаление знаков препинания и прочих символов, кроме русских/латинских букв и пробелов\n",
        "    - сжатие повторяющихся пробелов\n",
        "    - удаление цифр\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zа-яё\\s]', ' ', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\d+', ' ', text)  # Удаляем цифры\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def build_frequency_dictionary(token_lists) -> Counter:\n",
        "    \"\"\"Построение частотного словаря по списку списков токенов.\"\"\"\n",
        "    all_tokens = []\n",
        "    for tokens in token_lists:\n",
        "        if isinstance(tokens, list):\n",
        "            # Фильтруем очень короткие слова\n",
        "            filtered_tokens = [token for token in tokens if len(token) > 2]\n",
        "            all_tokens.extend(filtered_tokens)\n",
        "\n",
        "    freq = Counter(all_tokens)\n",
        "    return freq\n",
        "\n",
        "# Объединяем заголовок и текст новости\n",
        "df[\"full_text\"] = df[\"full_text\"].fillna(\"\")\n",
        "df[\"title\"] = df[\"title\"].fillna(\"\")\n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"full_text\"]\n",
        "\n",
        "# Очистка текста\n",
        "print(\"Очистка текста...\")\n",
        "df[\"clean_text\"] = df[\"text\"].astype(str).apply(clean_text)\n",
        "\n",
        "# Токенизация (по пробелу)\n",
        "print(\"Токенизация...\")\n",
        "df[\"tokens\"] = df[\"clean_text\"].apply(lambda x: x.split())\n",
        "\n",
        "# Частотный словарь\n",
        "print(\"Построение частотного словаря...\")\n",
        "freq_dict = build_frequency_dictionary(df[\"tokens\"])\n",
        "freq_df = pd.DataFrame(freq_dict.most_common(), columns=[\"word\", \"freq\"])\n",
        "\n",
        "print(\"\\nТоп-20 самых частотных слов:\")\n",
        "print(freq_df.head(20))\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(freq_dict)}\")\n",
        "print(f\"Всего слов в текстах: {sum(freq_dict.values())}\")\n",
        "\n",
        "# Bag of Words (BoW)\n",
        "print(\"\\nСоздание Bag of Words...\")\n",
        "vectorizer = CountVectorizer(\n",
        "    tokenizer=lambda x: x.split(),  # мы уже токенизируем через пробел\n",
        "    preprocessor=lambda x: x,       # текст уже очищен\n",
        "    max_features=1000,              # Ограничиваем размер словаря для наглядности\n",
        "    min_df=2                        # Слова, встречающиеся хотя бы в 2 документах\n",
        ")\n",
        "\n",
        "X_bow = vectorizer.fit_transform(df[\"clean_text\"])\n",
        "bow_df = pd.DataFrame(\n",
        "    X_bow.toarray(),\n",
        "    columns=vectorizer.get_feature_names_out()\n",
        ")\n",
        "\n",
        "print(\"Форма матрицы Bag of Words:\", X_bow.shape)\n",
        "print(f\"Размер словаря BoW: {len(vectorizer.get_feature_names_out())}\")\n",
        "\n",
        "# Показываем пример BoW представления\n",
        "print(\"\\nПример BoW представления для первой новости:\")\n",
        "first_row = bow_df.iloc[0]\n",
        "nonzero_cols = first_row[first_row > 0]\n",
        "print(f\"Ненулевых элементов: {len(nonzero_cols)}\")\n",
        "print(\"Слова с частотой > 0:\")\n",
        "for word, freq in nonzero_cols.head(10).items():\n",
        "    print(f\"  {word}: {int(freq)}\")"
      ],
      "metadata": {
        "id": "Z2R3N-hZg4Yq",
        "outputId": "ad9a3096-5297-406c-bcb8-05d1249080ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Очистка текста...\n",
            "Токенизация...\n",
            "Построение частотного словаря...\n",
            "\n",
            "Топ-20 самых частотных слов:\n",
            "          word  freq\n",
            "0          что    87\n",
            "1      декабря    39\n",
            "2        ранее    30\n",
            "3       словам    28\n",
            "4          как    26\n",
            "5          для    25\n",
            "6          она    20\n",
            "7         этом    19\n",
            "8          его    19\n",
            "9          это    18\n",
            "10      россии    16\n",
            "11         над    15\n",
            "12         сша    14\n",
            "13  президента    13\n",
            "14       также    13\n",
            "15       после    13\n",
            "16       время    12\n",
            "17        года    12\n",
            "18   президент    12\n",
            "19         том    11\n",
            "\n",
            "Всего уникальных слов: 2992\n",
            "Всего слов в текстах: 4777\n",
            "\n",
            "Создание Bag of Words...\n",
            "Форма матрицы Bag of Words: (50, 559)\n",
            "Размер словаря BoW: 559\n",
            "\n",
            "Пример BoW представления для первой новости:\n",
            "Ненулевых элементов: 34\n",
            "Слова с частотой > 0:\n",
            "  были: 1\n",
            "  в: 7\n",
            "  вечером: 1\n",
            "  взрывов: 1\n",
            "  взрывы: 4\n",
            "  говорится: 1\n",
            "  города: 1\n",
            "  данным: 2\n",
            "  декабря: 2\n",
            "  другие: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy3\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "def lemmatize_tokens(tokens, morph_analyzer) -> list[str]:\n",
        "    \"\"\"Лемматизация списка токенов с помощью pymorphy3.\"\"\"\n",
        "    lemmas = []\n",
        "    for token in tokens:\n",
        "        if len(token) > 2:  # Пропускаем очень короткие слова\n",
        "            try:\n",
        "                parsed = morph_analyzer.parse(token)[0]\n",
        "                lemmas.append(parsed.normal_form)\n",
        "            except:\n",
        "                lemmas.append(token)  # Если не удалось лемматизировать, оставляем как есть\n",
        "    return lemmas\n",
        "\n",
        "print(\"Лемматизация токенов...\")\n",
        "df[\"lemmas\"] = df[\"tokens\"].apply(lambda tokens: lemmatize_tokens(tokens, morph))\n",
        "df[\"lemmas_text\"] = df[\"lemmas\"].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "print(\"\\nПримеры обработки текста:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i in range(min(3, len(df))):\n",
        "    print(f\"\\nНовость {i+1}:\")\n",
        "    print(f\"Оригинальный заголовок: {df['title'].iloc[i][:100]}...\")\n",
        "    print(f\"Очищенный текст (первые 100 символов): {df['clean_text'].iloc[i][:100]}...\")\n",
        "    print(f\"Лемматизированный текст (первые 100 символов): {df['lemmas_text'].iloc[i][:100]}...\")\n",
        "    print(f\"Количество токенов: {len(df['tokens'].iloc[i])}\")\n",
        "    print(f\"Количество лемм: {len(df['lemmas'].iloc[i])}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Частотный словарь для лемматизированных текстов\n",
        "print(\"\\nСоздание частотного словаря для лемм...\")\n",
        "lemmas_freq_dict = build_frequency_dictionary(df[\"lemmas\"])\n",
        "lemmas_freq_df = pd.DataFrame(lemmas_freq_dict.most_common(), columns=[\"lemma\", \"freq\"])\n",
        "\n",
        "print(\"\\nТоп-20 самых частотных лемм:\")\n",
        "print(lemmas_freq_df.head(20))"
      ],
      "metadata": {
        "id": "F57nsojLg6-K",
        "outputId": "b8a0cb7d-82ce-4fa6-daee-45e3fb58d4f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лемматизация токенов...\n",
            "\n",
            "Примеры обработки текста:\n",
            "============================================================\n",
            "\n",
            "Новость 1:\n",
            "Оригинальный заголовок: В Киеве раздались взрывы01:41...\n",
            "Очищенный текст (первые 100 символов): в киеве раздались взрывы взрывы раздались в украинской столице на фоне воздушной тревоги об этом дек...\n",
            "Лемматизированный текст (первые 100 символов): киев раздаться взрыв взрыв раздаться украинский столица фон воздушный тревога это декабрь вtelegramс...\n",
            "Количество токенов: 67\n",
            "Количество лемм: 54\n",
            "----------------------------------------\n",
            "\n",
            "Новость 2:\n",
            "Оригинальный заголовок: В Европе подвели итоги противостояния с Россией01:41...\n",
            "Очищенный текст (первые 100 символов): в европе подвели итоги противостояния с россией противостояние с россией в рамках украинского конфли...\n",
            "Лемматизированный текст (первые 100 символов): европа подвести итог противостояние россия противостояние россия рамка украинский конфликт привести ...\n",
            "Количество токенов: 143\n",
            "Количество лемм: 112\n",
            "----------------------------------------\n",
            "\n",
            "Новость 3:\n",
            "Оригинальный заголовок: Жители российского региона сообщили о взрывах и вспышках01:39...\n",
            "Очищенный текст (первые 100 символов): жители российского региона сообщили о взрывах и вспышках в двух районах краснодарского края славянск...\n",
            "Лемматизированный текст (первые 100 символов): житель российский регион сообщить взрыв вспышка два район краснодарский край славянский темрюкский п...\n",
            "Количество токенов: 75\n",
            "Количество лемм: 58\n",
            "----------------------------------------\n",
            "\n",
            "Создание частотного словаря для лемм...\n",
            "\n",
            "Топ-20 самых частотных лемм:\n",
            "         lemma  freq\n",
            "0          что    89\n",
            "1          это    49\n",
            "2         быть    41\n",
            "3      декабрь    39\n",
            "4      который    33\n",
            "5       россия    31\n",
            "6        ранее    30\n",
            "7        слово    29\n",
            "8          год    28\n",
            "9          как    26\n",
            "10   президент    25\n",
            "11         для    25\n",
            "12  российский    24\n",
            "13         она    24\n",
            "14      страна    21\n",
            "15       путин    21\n",
            "16         тот    21\n",
            "17        свой    21\n",
            "18       глава    20\n",
            "19  украинский    18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация модели для эмбеддингов\n",
        "print(\"Загрузка модели для эмбеддингов...\")\n",
        "try:\n",
        "    # Используем модель, которая поддерживает русский язык\n",
        "    model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "    print(\"Модель успешно загружена!\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке модели: {e}\")\n",
        "    print(\"Попытка загрузить альтернативную модель...\")\n",
        "    try:\n",
        "        model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "        print(\"Альтернативная модель загружена!\")\n",
        "    except:\n",
        "        print(\"Не удалось загрузить модель. Создаем случайные эмбеддинги для демонстрации.\")\n",
        "        model = None\n",
        "\n",
        "# Получаем эмбеддинги\n",
        "print(\"\\nПолучение эмбеддингов для лемматизированных текстов...\")\n",
        "\n",
        "if model is not None:\n",
        "    # Используем реальную модель\n",
        "    embeddings = model.encode(\n",
        "        df[\"lemmas_text\"].tolist(),\n",
        "        convert_to_numpy=True,\n",
        "        show_progress_bar=True,\n",
        "        batch_size=16,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "else:\n",
        "    # Создаем случайные эмбеддинги для демонстрации\n",
        "    print(\"Создание случайных эмбеддингов...\")\n",
        "    embeddings = np.random.randn(len(df), 384)  # 384 - стандартная размерность для MiniLM\n",
        "    # Нормализуем\n",
        "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    embeddings = embeddings / norms\n",
        "\n",
        "print(f\"Форма матрицы эмбеддингов: {embeddings.shape}\")\n",
        "print(f\"Размерность одного эмбеддинга: {embeddings.shape[1]}\")\n",
        "\n",
        "# Сохраняем эмбеддинги в DataFrame\n",
        "# Для экономии памяти сохраняем только первые 10 измерений в основном DataFrame\n",
        "df[\"embedding_sample\"] = list(embeddings[:, :10])\n",
        "\n",
        "# Создаем отдельный DataFrame для полных эмбеддингов\n",
        "embedding_cols = [f\"emb_{i}\" for i in range(embeddings.shape[1])]\n",
        "embeddings_df = pd.DataFrame(embeddings, columns=embedding_cols)\n",
        "\n",
        "print(\"\\nПервые 3 эмбеддинга (первые 5 измерений):\")\n",
        "for i in range(min(3, len(embeddings))):\n",
        "    print(f\"Новость {i+1}: {embeddings[i, :5].round(4)}...\")\n",
        "\n",
        "# Анализ эмбеддингов\n",
        "print(\"\\nАнализ эмбеддингов:\")\n",
        "print(f\"Минимальное значение: {embeddings.min():.4f}\")\n",
        "print(f\"Среднее значение: {embeddings.mean():.4f}\")\n",
        "print(f\"Максимальное значение: {embeddings.max():.4f}\")\n",
        "print(f\"Стандартное отклонение: {embeddings.std():.4f}\")\n",
        "\n",
        "# Пример вычисления косинусного сходства между первыми двумя новостями\n",
        "if len(embeddings) >= 2:\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
        "    print(f\"\\nКосинусное сходство между новостью 1 и 2: {similarity:.4f}\")\n",
        "\n",
        "    # Сравнение заголовков\n",
        "    print(f\"Заголовок 1: {df['title'].iloc[0][:50]}...\")\n",
        "    print(f\"Заголовок 2: {df['title'].iloc[1][:50]}...\")"
      ],
      "metadata": {
        "id": "xKDqKNrCg9L7",
        "outputId": "06c19c2e-c597-4c47-d9c6-e7160d72dd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413,
          "referenced_widgets": [
            "d3fc0e33926f4588ab7d779d876af626",
            "6cf1c6e1e007434c92421b208dbfc6d0",
            "cb0222b926ef4f1fb86c3cb55ccfefea",
            "1bff470063a644f99d351916f5aadc26",
            "439aa4d682a34dbd984a83d4b81136d7",
            "127071d08d3040b69c051d86bd8c3197",
            "561fb8f3310b4a23aef2fe84c71573bb",
            "1a86693614bb408daf8c2fcedd45b2f4",
            "0994bba8810c43d88a27f837b78098f8",
            "0d1db8d1c59a48039dbf2e861a5161f2",
            "6356a0d2854c436f8b05944328ba99a4"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка модели для эмбеддингов...\n",
            "Модель успешно загружена!\n",
            "\n",
            "Получение эмбеддингов для лемматизированных текстов...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3fc0e33926f4588ab7d779d876af626"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Форма матрицы эмбеддингов: (50, 384)\n",
            "Размерность одного эмбеддинга: 384\n",
            "\n",
            "Первые 3 эмбеддинга (первые 5 измерений):\n",
            "Новость 1: [-0.0102  0.0649 -0.0072 -0.0299  0.0568]...\n",
            "Новость 2: [-0.0289  0.0426 -0.0898  0.0443  0.0571]...\n",
            "Новость 3: [ 0.0051  0.0253 -0.0057 -0.0201  0.0014]...\n",
            "\n",
            "Анализ эмбеддингов:\n",
            "Минимальное значение: -0.2041\n",
            "Среднее значение: 0.0001\n",
            "Максимальное значение: 0.3694\n",
            "Стандартное отклонение: 0.0510\n",
            "\n",
            "Косинусное сходство между новостью 1 и 2: 0.4819\n",
            "Заголовок 1: В Киеве раздались взрывы01:41...\n",
            "Заголовок 2: В Европе подвели итоги противостояния с Россией01:...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Сохраняем все данные\n",
        "print(\"Сохранение результатов...\")\n",
        "\n",
        "# 1. Основной DataFrame с текстами и признаками\n",
        "df.to_csv(\"news_with_features.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"✓ news_with_features.csv - основной DataFrame с текстами и признаками\")\n",
        "\n",
        "# 2. Частотный словарь исходных слов\n",
        "freq_df.to_csv(\"freq_dict_original.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"✓ freq_dict_original.csv - частотный словарь исходных слов\")\n",
        "\n",
        "# 3. Частотный словарь лемм\n",
        "lemmas_freq_df.to_csv(\"freq_dict_lemmas.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"✓ freq_dict_lemmas.csv - частотный словарь лемм\")\n",
        "\n",
        "# 4. Bag of Words матрица (первые 1000 признаков)\n",
        "bow_df.to_csv(\"bow_matrix.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"✓ bow_matrix.csv - матрица Bag of Words\")\n",
        "\n",
        "# 5. Полные эмбеддинги\n",
        "embeddings_df.to_csv(\"embeddings_full.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"✓ embeddings_full.csv - полные векторные представления\")\n",
        "\n",
        "# 6. Сводная статистика\n",
        "stats = {\n",
        "    \"total_news\": len(df),\n",
        "    \"avg_text_length\": df[\"text\"].str.len().mean(),\n",
        "    \"unique_words_original\": len(freq_dict),\n",
        "    \"unique_words_lemmas\": len(lemmas_freq_dict),\n",
        "    \"bow_vocabulary_size\": bow_df.shape[1],\n",
        "    \"embedding_dimension\": embeddings.shape[1],\n",
        "    \"avg_tokens_per_news\": df[\"tokens\"].apply(len).mean(),\n",
        "    \"avg_lemmas_per_news\": df[\"lemmas\"].apply(len).mean()\n",
        "}\n",
        "\n",
        "stats_df = pd.DataFrame([stats])\n",
        "stats_df.to_csv(\"processing_stats.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"✓ processing_stats.csv - статистика обработки\")\n",
        "\n",
        "# Создаем README файл с описанием\n",
        "readme_content = \"\"\"# Результаты обработки новостей\n",
        "\n",
        "## Файлы:\n",
        "\n",
        "1. **news_with_features.csv** - основной файл с новостями и признаками:\n",
        "   - date: дата новости\n",
        "   - title: заголовок\n",
        "   - link: ссылка\n",
        "   - full_text: полный текст\n",
        "   - text_length: длина текста\n",
        "   - text: объединенный текст (заголовок + полный текст)\n",
        "   - clean_text: очищенный текст\n",
        "   - tokens: токены (список)\n",
        "   - lemmas: леммы (список)\n",
        "   - lemmas_text: лемматизированный текст (строка)\n",
        "   - embedding_sample: первые 10 измерений эмбеддинга\n",
        "\n",
        "2. **freq_dict_original.csv** - частотный словарь исходных слов\n",
        "\n",
        "3. **freq_dict_lemmas.csv** - частотный словарь лемм\n",
        "\n",
        "4. **bow_matrix.csv** - матрица Bag of Words (1000 самых частых слов)\n",
        "\n",
        "5. **embeddings_full.csv** - полные векторные представления (эмбеддинги)\n",
        "\n",
        "6. **processing_stats.csv** - статистика обработки\n",
        "\n",
        "## Обработка включала:\n",
        "1. Парсинг 50 новостей с Lenta.ru\n",
        "2. Очистку текста (удаление пунктуации, цифр, приведение к нижнему регистру)\n",
        "3. Токенизацию\n",
        "4. Создание частотного словаря\n",
        "5. Кодирование в Bag of Words\n",
        "6. Лемматизацию с помощью pymorphy3\n",
        "7. Векторизацию с помощью Sentence-Transformers\n",
        "\"\"\"\n",
        "\n",
        "with open(\"README.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(readme_content)\n",
        "print(\"✓ README.txt - описание файлов и процесса обработки\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ВСЕ ФАЙЛЫ УСПЕШНО СОХРАНЕНЫ!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Показываем размеры файлов\n",
        "print(\"\\nРазмеры файлов:\")\n",
        "for filename in [\"news_with_features.csv\", \"freq_dict_original.csv\",\n",
        "                 \"freq_dict_lemmas.csv\", \"bow_matrix.csv\",\n",
        "                 \"embeddings_full.csv\"]:\n",
        "    if os.path.exists(filename):\n",
        "        size = os.path.getsize(filename) / 1024  # в КБ\n",
        "        print(f\"  {filename}: {size:.1f} КБ\")\n",
        "\n",
        "print(\"\\nДля скачивания файлов используйте:\")\n",
        "print(\"  from google.colab import files\")\n",
        "print(\"  files.download('имя_файла.csv')\")"
      ],
      "metadata": {
        "id": "r-L9LSH5hII7",
        "outputId": "5bed6cf8-e5ed-445c-f14c-fefeb91ca815",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сохранение результатов...\n",
            "✓ news_with_features.csv - основной DataFrame с текстами и признаками\n",
            "✓ freq_dict_original.csv - частотный словарь исходных слов\n",
            "✓ freq_dict_lemmas.csv - частотный словарь лемм\n",
            "✓ bow_matrix.csv - матрица Bag of Words\n",
            "✓ embeddings_full.csv - полные векторные представления\n",
            "✓ processing_stats.csv - статистика обработки\n",
            "✓ README.txt - описание файлов и процесса обработки\n",
            "\n",
            "============================================================\n",
            "ВСЕ ФАЙЛЫ УСПЕШНО СОХРАНЕНЫ!\n",
            "============================================================\n",
            "\n",
            "Размеры файлов:\n",
            "  news_with_features.csv: 511.7 КБ\n",
            "  freq_dict_original.csv: 58.2 КБ\n",
            "  freq_dict_lemmas.csv: 43.5 КБ\n",
            "  bow_matrix.csv: 62.2 КБ\n",
            "  embeddings_full.csv: 232.2 КБ\n",
            "\n",
            "Для скачивания файлов используйте:\n",
            "  from google.colab import files\n",
            "  files.download('имя_файла.csv')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3fc0e33926f4588ab7d779d876af626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cf1c6e1e007434c92421b208dbfc6d0",
              "IPY_MODEL_cb0222b926ef4f1fb86c3cb55ccfefea",
              "IPY_MODEL_1bff470063a644f99d351916f5aadc26"
            ],
            "layout": "IPY_MODEL_439aa4d682a34dbd984a83d4b81136d7"
          }
        },
        "6cf1c6e1e007434c92421b208dbfc6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_127071d08d3040b69c051d86bd8c3197",
            "placeholder": "​",
            "style": "IPY_MODEL_561fb8f3310b4a23aef2fe84c71573bb",
            "value": "Batches: 100%"
          }
        },
        "cb0222b926ef4f1fb86c3cb55ccfefea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a86693614bb408daf8c2fcedd45b2f4",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0994bba8810c43d88a27f837b78098f8",
            "value": 4
          }
        },
        "1bff470063a644f99d351916f5aadc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d1db8d1c59a48039dbf2e861a5161f2",
            "placeholder": "​",
            "style": "IPY_MODEL_6356a0d2854c436f8b05944328ba99a4",
            "value": " 4/4 [00:07&lt;00:00,  2.47s/it]"
          }
        },
        "439aa4d682a34dbd984a83d4b81136d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127071d08d3040b69c051d86bd8c3197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "561fb8f3310b4a23aef2fe84c71573bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a86693614bb408daf8c2fcedd45b2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0994bba8810c43d88a27f837b78098f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d1db8d1c59a48039dbf2e861a5161f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6356a0d2854c436f8b05944328ba99a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}